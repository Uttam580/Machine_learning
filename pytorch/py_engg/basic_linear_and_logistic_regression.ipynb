{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing librabries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1650'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Prepare data\n",
    "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast to float Tensor\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3475],\n",
      "        [ 0.3523],\n",
      "        [ 0.9547],\n",
      "        [ 0.0359],\n",
      "        [ 0.0480],\n",
      "        [ 0.0486],\n",
      "        [ 0.7233],\n",
      "        [ 0.8021],\n",
      "        [-1.1438],\n",
      "        [ 0.1794]])\n",
      "tensor([-126.2492,   50.9288,   63.1546,    6.0547,   -5.7295,   -2.7519,\n",
      "          58.7036,   53.8136,  -95.3411,   24.6481])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X[:10]), print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-126.2492],\n",
      "        [  50.9288],\n",
      "        [  63.1546],\n",
      "        [   6.0547],\n",
      "        [  -5.7295],\n",
      "        [  -2.7519],\n",
      "        [  58.7036],\n",
      "        [  53.8136],\n",
      "        [ -95.3411],\n",
      "        [  24.6481]])\n"
     ]
    }
   ],
   "source": [
    "y = y.view(y.shape[0], 1)\n",
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1, out_features=1, bias=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Model\n",
    "# Linear model f = wx + b\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "model = nn.Linear(input_size, output_size)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Loss and optimizer\n",
    "learning_rate = 0.01\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x000001B1F844E048>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss = 4114.8354\n",
      "epoch: 20, loss = 2897.8750\n",
      "epoch: 30, loss = 2068.5073\n",
      "epoch: 40, loss = 1503.1646\n",
      "epoch: 50, loss = 1117.7120\n",
      "epoch: 60, loss = 854.8544\n",
      "epoch: 70, loss = 675.5631\n",
      "epoch: 80, loss = 553.2466\n",
      "epoch: 90, loss = 469.7828\n",
      "epoch: 100, loss = 412.8198\n"
     ]
    }
   ],
   "source": [
    "# 3) Training loop\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass and loss\n",
    "    y_predicted = model(X)\n",
    "    loss = criterion(y_predicted, y)\n",
    "    \n",
    "    # Backward pass and update\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero grad before new step\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "predicted = model(X).detach().numpy()\n",
    "\n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "plt.plot(X_numpy, predicted, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "         1.189e-01],\n",
       "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "         8.902e-02],\n",
       "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "         8.758e-02],\n",
       "        ...,\n",
       "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "         7.820e-02],\n",
       "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "         1.240e-01],\n",
       "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "         7.039e-02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['malignant', 'benign'], dtype='<U9'),\n",
       " 'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry\\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        worst/largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 0 is Mean Radius, field\\n        10 is Radius SE, field 20 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
       " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "        'smoothness error', 'compactness error', 'concavity error',\n",
       "        'concave points error', 'symmetry error',\n",
       "        'fractal dimension error', 'worst radius', 'worst texture',\n",
       "        'worst perimeter', 'worst area', 'worst smoothness',\n",
       "        'worst compactness', 'worst concavity', 'worst concave points',\n",
       "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
       " 'filename': 'C:\\\\Users\\\\Uttam\\\\anaconda3\\\\envs\\\\envpytorch\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\breast_cancer.csv'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0) Prepare data\n",
    "bc = datasets.load_breast_cancer()\n",
    "bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = bc.data, bc.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, 1.001e+03, 1.184e-01, 2.776e-01,\n",
       "        3.001e-01, 1.471e-01, 2.419e-01, 7.871e-02, 1.095e+00, 9.053e-01,\n",
       "        8.589e+00, 1.534e+02, 6.399e-03, 4.904e-02, 5.373e-02, 1.587e-02,\n",
       "        3.003e-02, 6.193e-03, 2.538e+01, 1.733e+01, 1.846e+02, 2.019e+03,\n",
       "        1.622e-01, 6.656e-01, 7.119e-01, 2.654e-01, 4.601e-01, 1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, 1.326e+03, 8.474e-02, 7.864e-02,\n",
       "        8.690e-02, 7.017e-02, 1.812e-01, 5.667e-02, 5.435e-01, 7.339e-01,\n",
       "        3.398e+00, 7.408e+01, 5.225e-03, 1.308e-02, 1.860e-02, 1.340e-02,\n",
       "        1.389e-02, 3.532e-03, 2.499e+01, 2.341e+01, 1.588e+02, 1.956e+03,\n",
       "        1.238e-01, 1.866e-01, 2.416e-01, 1.860e-01, 2.750e-01, 8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, 1.203e+03, 1.096e-01, 1.599e-01,\n",
       "        1.974e-01, 1.279e-01, 2.069e-01, 5.999e-02, 7.456e-01, 7.869e-01,\n",
       "        4.585e+00, 9.403e+01, 6.150e-03, 4.006e-02, 3.832e-02, 2.058e-02,\n",
       "        2.250e-02, 4.571e-03, 2.357e+01, 2.553e+01, 1.525e+02, 1.709e+03,\n",
       "        1.444e-01, 4.245e-01, 4.504e-01, 2.430e-01, 3.613e-01, 8.758e-02],\n",
       "       [1.142e+01, 2.038e+01, 7.758e+01, 3.861e+02, 1.425e-01, 2.839e-01,\n",
       "        2.414e-01, 1.052e-01, 2.597e-01, 9.744e-02, 4.956e-01, 1.156e+00,\n",
       "        3.445e+00, 2.723e+01, 9.110e-03, 7.458e-02, 5.661e-02, 1.867e-02,\n",
       "        5.963e-02, 9.208e-03, 1.491e+01, 2.650e+01, 9.887e+01, 5.677e+02,\n",
       "        2.098e-01, 8.663e-01, 6.869e-01, 2.575e-01, 6.638e-01, 1.730e-01],\n",
       "       [2.029e+01, 1.434e+01, 1.351e+02, 1.297e+03, 1.003e-01, 1.328e-01,\n",
       "        1.980e-01, 1.043e-01, 1.809e-01, 5.883e-02, 7.572e-01, 7.813e-01,\n",
       "        5.438e+00, 9.444e+01, 1.149e-02, 2.461e-02, 5.688e-02, 1.885e-02,\n",
       "        1.756e-02, 5.115e-03, 2.254e+01, 1.667e+01, 1.522e+02, 1.575e+03,\n",
       "        1.374e-01, 2.050e-01, 4.000e-01, 1.625e-01, 2.364e-01, 7.678e-02]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.view(y_train.shape[0], 1)# reshaping the data to one col.\n",
    "y_test = y_test.view(y_test.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Model\n",
    "# Linear model f = wx + b , sigmoid at the end\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "\n",
    "model = Model(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (linear): Linear(in_features=30, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Loss and optimizer\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()#applying binary cross entropy loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss = 0.7023\n",
      "epoch: 20, loss = 0.5597\n",
      "epoch: 30, loss = 0.4750\n",
      "epoch: 40, loss = 0.4191\n",
      "epoch: 50, loss = 0.3791\n",
      "epoch: 60, loss = 0.3487\n",
      "epoch: 70, loss = 0.3248\n",
      "epoch: 80, loss = 0.3053\n",
      "epoch: 90, loss = 0.2890\n",
      "epoch: 100, loss = 0.2752\n"
     ]
    }
   ],
   "source": [
    "# 3) Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass and loss\n",
    "    y_pred = model(X_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "\n",
    "    # Backward pass and update\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero grad before new step\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9737\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test)\n",
    "    y_predicted_cls = y_predicted.round()\n",
    "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "    print(f'accuracy: {acc.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
